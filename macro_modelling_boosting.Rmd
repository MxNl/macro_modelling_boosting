---
title: "MACRO - Mapping hydrogeochemical parameters using machine learning"
subtitle: "Training a XGBoost model"
author: "Maximilian NÃ¶lscher"
date: "`r format(Sys.time(), '%d/%m/%Y')`"
output:
  html_document:
    theme: lumen
    highlight: tango
    toc: TRUE
    toc_float: TRUE
    collapse: FALSE
    toc_depth: 3
    collapsed: FALSE
    smooth_scroll: FALSE
    number_sections: TRUE
    self_contained: yes
    df_print: paged
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(out.width = "100%")
options(tidyverse.quiet = TRUE)
```

```{r}
library(skimr)
library(visdat)
library(knitr)
```

```{r, echo = FALSE}
source("R/processing_functions.R")
source("R/markdown.R")
source("R/constants.R")
```


This report summarizes the results of code written with the purpose to

- do explanatory data analysis (EDA) on the features and the target variables
- set up an xgboost model
- tune hyperparameters
- evaluate the model

# Data Import
## Hydrocheocamical Parameters (target variables)
```{r, echo = TRUE}
data_targets <- 
  tar_read(back_vals_filter_sf) %>% 
  st_drop_geometry() %>% 
  as_tibble()

data_targets
```
## Features

```{r}
data_features <- 
  tar_read(data_features_depth_added)
```


# Exploratory Analysis

## Target Variables

For a first impression of the target variables we print the summary of simple statistical properties.
```{r}
data_targets %>% 
  select(one_of(HYDROGEOCHEMICAL_PARAMS_MAJOR_IONS)) %>% 
  skim()
```

As a next step we look at the data types and missing values.
```{r}
data_targets %>%
  select(one_of(HYDROGEOCHEMICAL_PARAMS_MAJOR_IONS)) %>% 
  set_names(parameter_pretty_markdown(names(.), with_unit = FALSE, markdown = FALSE)) %>% 
  vis_dat(warn_large_data = FALSE)
```
**Need for action:** All parameters have missing values, which will be removed after joining the single parameter with the features as the missing values occure in different samples.


One way to get an overview of the values is to plot them individually after rescaling to the range from 0 to 1.
```{r}
data_targets %>% 
  select(one_of(HYDROGEOCHEMICAL_PARAMS_MAJOR_IONS)) %>%
  set_names(parameter_pretty_markdown(names(.), with_unit = FALSE, markdown = FALSE)) %>% 
  vis_value() +
  guides(fill = guide_legend(title = "Value\n(rescaled)"))
```

To check how the distributions of each target variable looks like, we visualize their values in a violine plot.
```{r}
tar_read(plot_violin_distribution_targets)
```
Alternativle, to also see the true and unscaled values we can additionally plot histograms.
```{r, fig.height=8}
data_targets %>% 
  select(one_of(HYDROGEOCHEMICAL_PARAMS_MAJOR_IONS)) %>%
  set_names(parameter_pretty_markdown(names(.), with_unit = FALSE, bold = TRUE)) %>% 
  pivot_longer(cols = everything()) %>% 
  drop_na(value) %>%
  # group_by(name) %>% 
  # summarise(min = min(value),
  #           max = max(value))
  ggplot(aes(value)) +
  geom_histogram(fill = COLOUR_HEX_BAR_FILL,
                 boundary = 0) +
  scale_y_log10() +
      theme_minimal() +
      labs(x = "Concentration [mg/L]",
           y = "Count",
           fill = "",
           alpha = ALPHA_BARS) +
      theme(
        plot.subtitle = element_markdown(),
        plot.title = element_markdown(),
        axis.text.y = element_markdown(),
        legend.text = element_markdown(),
        # strip.background = element_blank(),
        strip.text.x = element_markdown()
        ) +
  facet_wrap(~name, ncol = 2, scales = "free_x")
```

**Need for action:** We can see that all parameters have some negative values which does not make sense for concentrations with the unit mg/L. This will handled later.

## Features

Due to the large number (`r data_features %>% select(-station_id) %>% ncol()`) of features, it's hardly possible to plot all features at once. Therefore a smaller random subset will be plotted.
Analog to the target variables we try to get an overview of the features.

```{r}
data_features %>% 
  select(-station_id) %>% 
  skim()
```

As a next step we look at the data types and missing values.
```{r}
data_features %>% 
  select(-station_id) %>% 
  set_names(as.character(1:ncol(.))) %>% 
  vis_dat(warn_large_data = FALSE) +
  theme(axis.text.x = element_blank(),
        legend.position = "top",
        legend.justification = "left") +
  labs(x = "Feature")
```

One way to get an overview of the values is to plot them individually after rescaling to the range from 0 to 1.
```{r}
data_features %>% 
  select(-station_id) %>% 
  vis_value() +
  theme(axis.text.x = element_blank(),
        legend.position = "top",
        legend.justification = "left") +
  labs(x = "Feature")
```



Alternativle, to also see the true and unscaled values we can additionally plot histograms.
```{r, fig.height=10}
tar_read(plot_histogram_distribution_features)
```


Now, we can look at the correlations between the highest correlated features.
```{r, echo = TRUE, fig.height=8}
tar_read(interactive_correlation_plot)
```

# Preprocessing

# Modelling

## Best Hyperparameters {.tabset}

The following table summarises the hyperparameters of the best model configuration according to tuning process.
```{r, echo = FALSE, results = "asis"}
model_params <- tar_read(xgboost_model_final_params)

model_params %>% 
  imap(~mutate(.x, parameter = .y, .before = 1)) %>% 
  reduce(bind_rows) %>% 
  mutate(parameter = parameter_pretty_markdown(parameter, with_unit = FALSE)) %>% 
  kable()
```

...or shown separately for each parameter and as bar chart.

```{r, echo = FALSE, results = "asis"}
model_params <- tar_read(xgboost_model_final_params)

plots_model_params <- 
  model_params %>% 
  map(function(.x) {
    .x %>% 
      pivot_longer(cols = -".config") %>% 
      mutate(value = signif(value, 3)) %>% 
      mutate(name = str_replace_all(name, "_", " ")) %>% 
      ggplot(aes(name, value, label = value)) +
      geom_col(fill = COLOUR_HEX_BAR_FILL,
               alpha = ALPHA_BARS) +
      geom_label() +
      theme_minimal() +
      labs(x = "parameter")
  })

tar_read(parameters_to_model) %>%
  parameter_pretty_markdown(with_unit = FALSE) %>% 
  map2(plots_model_params, ~create_section(.y, .x, 3))
```

# Evaluation

## Performance {.tabset}
```{r, echo = FALSE, results = "asis"}
plot_observed_vs_predicted <- tar_read(plot_observed_vs_predicted)
plot_residuals_vs_predicted <- tar_read(plot_residuals_vs_predicted)

names_pretty <-
  plot_observed_vs_predicted %>%
  names() %>%
  parameter_pretty_markdown(with_unit = FALSE)

for (i in seq_along(names_pretty)) {
  create_section_results(plot_observed_vs_predicted[[i]],
                         plot_residuals_vs_predicted[[i]],
                         names_pretty[[i]],
                         3)
}

# plot_observed_vs_predicted %>%
#   names() %>%
#   parameter_pretty_markdown(with_unit = FALSE) %>%
#   list(plot_observed_vs_predicted,
#        plot_residuals_vs_predicted) %>%
#   pmap(~create_section_results(..2, ..1, ..3, 3))
```

## Feature Importance {.tabset}

```{r, echo = FALSE, results = "asis"}
plot_feature_importance <- tar_read(plot_feature_importance)

plot_feature_importance %>%
  names() %>%
  parameter_pretty_markdown(with_unit = FALSE) %>% 
  map2(plot_feature_importance, ~create_section(.y, .x, 3))
```
